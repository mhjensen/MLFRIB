<p><strong></strong></p>
<p>Machine Learning and Artificial Intelligence activities at FRIB</p>
<h1 id="explanation">Explanation</h1>
<p>The purpose of this document is to collect information about the competence in the area of ML/AI at FRIB Laboratory. This is important, e.g., for the upcoming <a href="https://www.jlab.org/conference/AI2020"><em>AI FOR NUCLEAR PHYSICS WORKSHOP</em></a> at JLab, March 4-6, 2020 and other related activities.</p>
<h2 id="description-of-individual-entries">Description of individual entries</h2>
<p>Please format your entry (1 entry per page) according to the following template:</p>
<h1 id="machine-learning-and-ai-in-nuclear-physics">Machine Learning and AI in Nuclear Physics</h1>
<p>Artificial intelligence (AI)-based techniques, particularly in machine learning (ML) and optimization, are increasingly being used in many areas of experimental and theoretical physics to facilitate discovery, accelerate data analysis and modeling efforts, and bridge different physical and temporal scales in numerical models. The large amount of degrees of freedom pertain to both theory and experiment in nuclear physics. With increasingly complicated experiments that produce large amounts data, automated classification of events becomes increasingly important. Artificial intelligence and Machine Learning techniques are proving to be powerful tools for advancing our understanding of the physics from complicated nuclear systems.</p>
<h2 id="types-of-machine-learning">Types of Machine Learning</h2>
<p>The approaches to machine learning are many, but are often split into two main categories. In <em>supervised learning</em> we know the answer to a problem, and let the computer deduce the logic behind it. On the other hand, <em>unsupervised learning</em> is a method for finding patterns and relationship in data sets without any prior knowledge of the system. Some authors also operate with a third category, namely <em>reinforcement learning</em>. This is a paradigm of learning inspired by behavioural psychology, where learning is achieved by trial-and-error, solely from rewards and punishment.</p>
<p>Another way to categorize machine learning tasks is to consider the desired output of a system. Some of the most common tasks are:</p>
<ul>
<li><p>Classification: Outputs are divided into two or more classes. The goal is to produce a model that assigns inputs into one of these classes. An example is to identify digits based on pictures of hand-written ones. Classification is typically supervised learning.</p></li>
<li><p>Regression: Finding a functional relationship between an input data set and a reference data set. The goal is to construct a function that maps input data to continuous output values.</p></li>
<li><p>Clustering: Data are divided into groups with certain common traits, without knowing the different groups beforehand. It is thus a form of unsupervised learning.</p></li>
</ul>
<p>These categories are all part of the broad spectrum of AI and ML techniques being studied at FRIB.</p>
<h2 id="glossary-of-machine-learningstatistical-terms-used">Glossary of machine learning/statistical terms used</h2>
<p>We list here various acronyms used in the description of the different AI/ML projects.</p>
<dl>
<dt>AI</dt>
<dd><p>Artificial intelligence</p>
</dd>
<dt>BMA</dt>
<dd><p>Bayesian Model Averaging</p>
</dd>
<dt>CoD</dt>
<dd><p>Coefficient of determination</p>
</dd>
<dt>GP</dt>
<dd><p>Gaussian processes</p>
</dd>
<dt>MCMC</dt>
<dd><p>Markov chain Monte Carlo</p>
</dd>
<dt>ML</dt>
<dd><p>Machine learning</p>
</dd>
<dt>NN</dt>
<dd><p>Neural networks</p>
</dd>
<dt>PCA</dt>
<dd><p>Principal component analysis and dimensionality Reduction Techniques</p>
</dd>
<dt>UQ</dt>
<dd><p>Uncertainty quantification</p>
</dd>
<dt>BM</dt>
<dd><p>Boltzmann Machines and Reduced Boltzmann Machines</p>
</dd>
<dt>RNN</dt>
<dd><p>Recurrent Neural Networks</p>
</dd>
<dt>CNN</dt>
<dd><p>Convolutional Neural Networks</p>
</dd>
<dt>AE</dt>
<dd><p>Auto Encoders</p>
</dd>
<dt>VAE</dt>
<dd><p>Variational Auto Encoders</p>
</dd>
<dt>BML</dt>
<dd><p>Bayesian Machine Learning</p>
</dd>
<dt>CL</dt>
<dd><p>Clustering</p>
</dd>
<dt>LSTM</dt>
<dd><p>Long Short-Term Memory</p>
</dd>
<dt>RL</dt>
<dd><p>Reinforcement Learning</p>
</dd>
<dt>FS</dt>
<dd><p>Frequentist Statistics</p>
</dd>
<dt>BS</dt>
<dd><p>Bayesian Statistics</p>
</dd>
<dt>DRB</dt>
<dd><p>Decision Trees, Random Forests and Boosting</p>
</dd>
<dt>SVM</dt>
<dd><p>Support Vector Machines</p>
</dd>
<dt>LR</dt>
<dd><p>Logistic Regression</p>
</dd>
<dt>REG</dt>
<dd><p>Linear Regression and beyond</p>
</dd>
<dt>GM</dt>
<dd><p>Graphical Models</p>
</dd>
</dl>
<h1 id="aiml-projects-at-frib">AI/ML projects at FRIB</h1>
<h2 id="accelerators">Accelerators</h2>
<h3 id="add-title">Add title</h3>
<h2 id="detectors">Detectors</h2>
<h3 id="add-title-1">Add title</h3>
<h2 id="data-analysis-and-statistical-analysis">Data Analysis and Statistical Analysis</h2>
<h3 id="add-title-2">Add title</h3>
<h2 id="basic-research">Basic Research</h2>
<h3 id="quantified-limits-of-the-nuclear-landscape">Quantified limits of the nuclear landscape</h3>
<figure>
<embed src="figures/Landscape.pdf" /><figcaption> The quantified landscape of nuclear existence obtained in our BMA calculations. For every nucleus with <span class="math inline"><em>Z</em>, <em>N</em> ≥ 8</span> and <span class="math inline"><em>Z</em> ≤ 119</span> the probability that the nucleus is bound with respect to proton and neutron decay, is marked. The domains of nuclei which have been experimentally observed and whose separation energies have been measured (and used for training) are indicated together with the experimental reach of FRIB. </figcaption>
</figure>
<h3 id="deep-learning-and-the-nuclear-many-body-problem">Deep Learning and the Nuclear Many-Body Problem</h3>
<h2 id="applications">Applications</h2>
<h1 id="education-and-work-force-development">Education and Work force development</h1>
<p>AI, ML, statistical data analysis and related areas are expected to play an ever-increasing role in many areas, from fundamental and applied research at universities and national laboratories to applications and developments in both the private and the public sectors. Developing basic research activities in these frontier computational technologies is thus of strategic importance for our society’s capability to address future scientific problems. Transfer of knowledge to other disciplines and sectors, as well as developing lasting collaborations with partners outside the traditional university sector, are themes we expect will benefit society at large and that will play central roles. Nuclear Physics keeps attracting many brilliant young researchers and providing our work force with these competences and skills for solving complicated physics problems is a compelling task for our community.</p>
<ul>
<li><p>In order to develop education and training efforts that target AI and ML related methods applied to Nuclear Physics, we organized in 2019 a four day long FRIB-TA workshop on ML methods in Nuclear physics at the NSCL/FRIB, with more than 100 participants.</p></li>
<li><p>In 2020 several of us (Bazin, Hjorth-Jensen and Liddick) will teach a three-week long Nuclear Talent course on Machine Learning and Data Analysis applied to nuclear physics.</p></li>
<li><p>We initiated the series of meetings on <span><em>Enhancing the interaction between nuclear experiment and theory through information and statistics</em></span> <a href="https://iopscience.iop.org/journal/0954-3899/page/ISNET">(ISNET)</a>. The next ISNET-8 will be held at FRIB during Dec. 14-17th, 2020.</p></li>
</ul>
